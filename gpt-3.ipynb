{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a96bfbd-e5fd-40e7-8868-2a27ee8e7205",
   "metadata": {},
   "source": [
    "### GPT-3 Test and Learn\n",
    "Copied from https://blog.dspaces.io/2021/04/15/a-test-and-learn-approach-to-developing-with-openais-gpt-3/\n",
    "I only changed it to work with a CSV instead of Google BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "276c6e4c-7fb8-4158-a8ad-6dafd32ed445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# OpenAI Key\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.environ.get('OPENAI_KEY')\n",
    "openai.api_key = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c70b9d4-9715-4ef0-ae97-dffd72105f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name your project and define a goal\n",
    "project_name = \"openai_test_and_learn\"\n",
    "project_goal = \"Build a test and learn framework around developing on the OpenAI GPT-3 API\"\n",
    "project_details = {\n",
    "    \"project_name\": project_name,\n",
    "    \"project_goal\": project_goal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be104b1d-c404-4c8d-bec4-a12eed26913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(user_input):\n",
    "    \"\"\"\n",
    "    Background: This function takes the parameter user_input and incorporates it into the prompt.\n",
    "    \n",
    "    Params:\n",
    "        - user_input (str): User generated input that we will pass into the prompt. Ex: 'Once upon a time'\n",
    "    \n",
    "    Returns: \n",
    "        - prompt (str): The prompt that includes user_input and will be sent along with the GPT-3 request.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # The first line describes what we want GPT-3 to do. \n",
    "    prompt = f\"\"\"Create a story about exploring the moon.\n",
    "    \n",
    "{user_input}\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fc6ffbf-9566-4047-ad3d-09636b51c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_openai_experiment(params, project_details):\n",
    "    \n",
    "    \"\"\"\n",
    "    Background: This function captures all details about a request to the OpenAI API and saves this data to CSV.\n",
    "    \n",
    "    Params:\n",
    "        - params (dict): Contains all of the parameters used in an OpenAI GPT-3 request\n",
    "     \n",
    "    Returns:\n",
    "        df: A dataframe with details about the request + response\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a Timestamp\n",
    "    timestamp = datetime.datetime.now()\n",
    "    \n",
    "    # Print Prompt\n",
    "    print('*** PROMPT ***')\n",
    "    print(params['prompt'])\n",
    "    \n",
    "    # Make a request to OpenAI using the selected params\n",
    "    response = openai.Completion.create(\n",
    "      engine=params['engine'],\n",
    "      prompt=params['prompt'],\n",
    "      max_tokens=params['max_tokens'],\n",
    "      temperature=params['temperature'],\n",
    "      top_p=params['top_p'],\n",
    "      frequency_penalty=params['frequency_penalty'],\n",
    "      presence_penalty=params['presence_penalty'],  \n",
    "      n=params['n'],\n",
    "      stream = params['stream'],\n",
    "      logprobs=params['logprobs'],\n",
    "      stop = params['stop']\n",
    "    )\n",
    "    \n",
    "    # Parse out the response   \n",
    "    response_text = response.choices[0]['text']\n",
    "    response_id = response['id']\n",
    "    response_model = response['model']\n",
    "    response_object = response['object']\n",
    "            \n",
    "    # Display the output to the user\n",
    "    print('*** RESPONSE FROM OPENAI ***')\n",
    "    print(response_text)\n",
    "    \n",
    "    # Prompt satisfaction question\n",
    "    satisfaction_score = input('Please rate the quality of this output from 1 to 10, where 1 is not at all satisfied and 10 is extremely satisfied:\\n ')\n",
    "    \n",
    "    # Record observations about the output\n",
    "    observations = input(\"Please note any observations about the output - eg. how to improve / changes made / etc:\\n \")\n",
    "    \n",
    "    # Gather all of our data about the initial request, response and our observations\n",
    "    data = {\n",
    "        'timestamp':timestamp,\n",
    "        'project_name': project_details['project_name'],\n",
    "        'project_goal': project_details['project_goal'],\n",
    "        'prompt': params['prompt'],        \n",
    "        'response_text': response_text,\n",
    "        'satisfaction_score':satisfaction_score,\n",
    "        'observations':observations,\n",
    "        'response_id': response_id,\n",
    "        'response_model': response_model,\n",
    "        'response_object': response_object,\n",
    "        'response_length': len(response_text),\n",
    "        'prompt_length': len(params['prompt']),\n",
    "        'engine':params['engine'],      \n",
    "        'max_tokens':params['max_tokens'],\n",
    "        'temperature':params['temperature'],\n",
    "        'top_p':params['top_p'],\n",
    "        'frequency_penalty':params['frequency_penalty'],\n",
    "        'presence_penalty':params['presence_penalty'],        \n",
    "        'n':params['n'],\n",
    "        'stream':params['stream'],\n",
    "        'logprobs':params['logprobs'],\n",
    "        'stop':params['stop']\n",
    "    }    \n",
    "    \n",
    "    # Create a dataframe based on data    \n",
    "    df = pd.DataFrame([data])\n",
    "    \n",
    "    # Send data to CSV, merge if db exists\n",
    "    db_name = \"gpt_responses.csv\"\n",
    "    if os.path.isfile(db_name):\n",
    "        db = pd.read_csv(db_name)\n",
    "        df = db.append(df)\n",
    "        df.to_csv(db_name)\n",
    "        \n",
    "    else:\n",
    "        df.to_csv(db_name)\n",
    "        \n",
    "    print(f\"The following data successfully saved to CSV '{db_name}':\")\n",
    "    \n",
    "    return df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c78589a-05ba-4222-9f3f-58e361022486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** PROMPT ***\n",
      "Create a story about exploring the moon.\n",
      "    \n",
      "Once upon a time,\n",
      "*** RESPONSE FROM OPENAI ***\n",
      " there was a man who wanted to go to the moon. He wanted to go to the moon because he wanted to see what it was like. He wanted to see if it was really as beautiful as people said it was. He wanted to see if\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please rate the quality of this output from 1 to 10, where 1 is not at all satisfied and 10 is extremely satisfied:\n",
      "  9\n",
      "Please note any observations about the output - eg. how to improve / changes made / etc:\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following data successfully saved to CSV 'gpt_responses.csv':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>project_name</th>\n",
       "      <th>project_goal</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_text</th>\n",
       "      <th>satisfaction_score</th>\n",
       "      <th>observations</th>\n",
       "      <th>response_id</th>\n",
       "      <th>response_model</th>\n",
       "      <th>...</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_tokens</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>frequency_penalty</th>\n",
       "      <th>presence_penalty</th>\n",
       "      <th>n</th>\n",
       "      <th>stream</th>\n",
       "      <th>logprobs</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-04-22 18:19:24.287694</td>\n",
       "      <td>openai_test_and_learn</td>\n",
       "      <td>Build a test and learn framework around develo...</td>\n",
       "      <td>Create a story about exploring the moon.\\n    ...</td>\n",
       "      <td>there was a family who had a son. He was the ...</td>\n",
       "      <td>8</td>\n",
       "      <td>didnt mention the moon</td>\n",
       "      <td>cmpl-2rXH3E6nWdWsvCvljH0NQ1ESeVFjd</td>\n",
       "      <td>davinci:2020-05-03</td>\n",
       "      <td>...</td>\n",
       "      <td>davinci</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-22 18:20:00.973071</td>\n",
       "      <td>openai_test_and_learn</td>\n",
       "      <td>Build a test and learn framework around develo...</td>\n",
       "      <td>Create a story about exploring the moon.\\n    ...</td>\n",
       "      <td>there was a man who wanted to go to the moon....</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>cmpl-2rXHdnpmLPHLA5ikXO30Qz9EEkoNn</td>\n",
       "      <td>davinci:2020-05-03</td>\n",
       "      <td>...</td>\n",
       "      <td>davinci</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   timestamp           project_name  \\\n",
       "0         0.0  2021-04-22 18:19:24.287694  openai_test_and_learn   \n",
       "0         NaN  2021-04-22 18:20:00.973071  openai_test_and_learn   \n",
       "\n",
       "                                        project_goal  \\\n",
       "0  Build a test and learn framework around develo...   \n",
       "0  Build a test and learn framework around develo...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Create a story about exploring the moon.\\n    ...   \n",
       "0  Create a story about exploring the moon.\\n    ...   \n",
       "\n",
       "                                       response_text satisfaction_score  \\\n",
       "0   there was a family who had a son. He was the ...                  8   \n",
       "0   there was a man who wanted to go to the moon....                  9   \n",
       "\n",
       "             observations                         response_id  \\\n",
       "0  didnt mention the moon  cmpl-2rXH3E6nWdWsvCvljH0NQ1ESeVFjd   \n",
       "0                          cmpl-2rXHdnpmLPHLA5ikXO30Qz9EEkoNn   \n",
       "\n",
       "       response_model  ...   engine  max_tokens  temperature top_p  \\\n",
       "0  davinci:2020-05-03  ...  davinci          50          1.0   0.5   \n",
       "0  davinci:2020-05-03  ...  davinci          50          1.0   0.5   \n",
       "\n",
       "   frequency_penalty  presence_penalty  n  stream  logprobs  stop  \n",
       "0                  0                 0  1     NaN       NaN   NaN  \n",
       "0                  0                 0  1    None      None  None  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The opening line to our story we want GPT-3 to build on.\n",
    "user_input = 'Once upon a time,'\n",
    "\n",
    "# Let's take user_input and use it to generate a prompt\n",
    "my_prompt = build_prompt(user_input)\n",
    "\n",
    "# GPT-3 Request parameters\n",
    "model_params = {\n",
    "    'engine': 'davinci',\n",
    "    'prompt': my_prompt,\n",
    "    'max_tokens': 50,\n",
    "    'temperature': 1.0,\n",
    "    'top_p': 0.5,\n",
    "    'frequency_penalty': 0,\n",
    "    'presence_penalty': 0,\n",
    "    'n': 1,\n",
    "    'stream': None,\n",
    "    'logprobs': None,\n",
    "    'stop':None\n",
    "}\n",
    "\n",
    "# Pass in GPT-3 model parameters and project details. \n",
    "run_openai_experiment(model_params, project_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f0064-e38c-4341-9a79-9565f1a72cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
